# üè¶ Neo-Bank Credit Scoring Model
# Cr√©ation d'un mod√®le 
# OBJECTIF: Mod√®le qui fonctionne sur Streamlit Cloud 

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
import pickle
import warnings
import os
warnings.filterwarnings('ignore')

print("üöÄ CR√âATION MOD√àLE NEO-BANK ")
print("="*50)

# V√©rification de la version
import sklearn
print(f"üìå Version scikit-learn: {sklearn.__version__}")

# 1. CR√âATION DE DONN√âES SYNTH√âTIQUES R√âALISTES
print("\nüìä CR√âATION DU DATASET SYNTH√âTIQUE")
print("="*40)

np.random.seed(42)  # Pour la reproductibilit√©
n_samples = 5000

print(f"üìã G√©n√©ration de {n_samples} √©chantillons...")

# G√©n√©ration de donn√©es r√©alistes pour le cr√©dit
data_list = []

for i in range(n_samples):
    # Revenus annuels (distribution log-normale)
    income = np.random.lognormal(mean=10.5, sigma=0.7)
    income = max(15000, min(income, 300000))  # Entre 15k et 300k
    
    # Montant du cr√©dit demand√© (2x √† 8x les revenus)
    credit_multiplier = np.random.uniform(2, 8)
    credit_amount = income * credit_multiplier
    
    # Annuit√©s mensuelles (5% √† 20% des revenus annuels / 12)
    annuity_rate = np.random.uniform(0.05, 0.20)
    annuity = (income * annuity_rate) / 12
    
    # √Çge (distribution normale centr√©e sur 40 ans)
    age = max(18, min(70, int(np.random.normal(40, 12))))
    
    # Ann√©es d'emploi (distribution exponentielle)
    employment_years = max(0, min(40, int(np.random.exponential(7))))
    
    # Ratios financiers calcul√©s
    credit_income_ratio = credit_amount / income
    annuity_income_ratio = annuity / income
    
    # Variables famille
    family_size = max(1, min(6, int(np.random.poisson(2.3))))
    children_ratio = max(0, min(1, np.random.beta(2, 5)))
    
    # Score externe moyen (sources externes de cr√©dit)
    external_sources_mean = np.random.beta(5, 5)
    
    # Variables cat√©gorielles encod√©es
    education_encoded = np.random.randint(0, 5)
    income_type_encoded = np.random.randint(0, 4)
    family_status_encoded = np.random.randint(0, 4)
    code_gender = np.random.randint(0, 2)  # 0=F, 1=M
    
    # CALCUL DU RISQUE BAS√â SUR DES R√àGLES M√âTIER R√âALISTES
    risk_score = 0
    
    # Facteur 1: Ratio cr√©dit/revenus
    if credit_income_ratio > 6:
        risk_score += 0.4
    elif credit_income_ratio > 4:
        risk_score += 0.2
    elif credit_income_ratio > 3:
        risk_score += 0.1
    
    # Facteur 2: Taux d'endettement
    if annuity_income_ratio > 0.35:
        risk_score += 0.3
    elif annuity_income_ratio > 0.25:
        risk_score += 0.15
    
    # Facteur 3: √Çge
    if age < 25:
        risk_score += 0.15
    elif age > 65:
        risk_score += 0.1
    elif 30 <= age <= 50:
        risk_score -= 0.05  # √Çge optimal
    
    # Facteur 4: Stabilit√© professionnelle
    if employment_years < 1:
        risk_score += 0.25
    elif employment_years < 3:
        risk_score += 0.1
    elif employment_years > 10:
        risk_score -= 0.1  # Bonus stabilit√©
    
    # Facteur 5: Niveau de revenus
    if income < 25000:
        risk_score += 0.15
    elif income > 75000:
        risk_score -= 0.05
    
    # Facteur 6: Situation familiale
    if family_size > 4:
        risk_score += 0.05
    
    # Ajout de variabilit√© al√©atoire
    risk_score += np.random.normal(0, 0.1)
    
    # D√©cision binaire (TARGET: 1=d√©faut, 0=remboursement)
    # Seuil ajust√© pour avoir ~8% de d√©faut comme dans la r√©alit√©
    target = 1 if risk_score > 0.6 else 0
    
    # Construction de la ligne de donn√©es
    row = [
        income,                 # AMT_INCOME_TOTAL
        credit_amount,          # AMT_CREDIT  
        annuity,                # AMT_ANNUITY
        age,                    # AGE_YEARS
        employment_years,       # EMPLOYMENT_YEARS
        credit_income_ratio,    # CREDIT_INCOME_RATIO
        annuity_income_ratio,   # ANNUITY_INCOME_RATIO
        family_size,            # FAMILY_SIZE
        children_ratio,         # CHILDREN_RATIO
        external_sources_mean,  # EXTERNAL_SOURCES_MEAN
        education_encoded,      # EDUCATION_ENCODED
        income_type_encoded,    # INCOME_TYPE_ENCODED
        family_status_encoded,  # FAMILY_STATUS_ENCODED
        code_gender,            # CODE_GENDER
        target                  # TARGET
    ]
    
    data_list.append(row)

# Conversion en DataFrame
feature_names = [
    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',
    'AGE_YEARS', 'EMPLOYMENT_YEARS', 
    'CREDIT_INCOME_RATIO', 'ANNUITY_INCOME_RATIO',
    'FAMILY_SIZE', 'CHILDREN_RATIO',
    'EXTERNAL_SOURCES_MEAN',
    'EDUCATION_ENCODED', 'INCOME_TYPE_ENCODED', 
    'FAMILY_STATUS_ENCODED', 'CODE_GENDER'
]

columns = feature_names + ['TARGET']
df = pd.DataFrame(data_list, columns=columns)

print(f"‚úÖ Dataset cr√©√©: {df.shape}")
print(f"üìä Taux de d√©faut: {df['TARGET'].mean():.1%}")
print(f"üìã Variables: {len(feature_names)} features")

# V√©rification des donn√©es
print("\nüìà STATISTIQUES DU DATASET")
print("="*30)
print("Revenus moyens:", f"{df['AMT_INCOME_TOTAL'].mean():,.0f}‚Ç¨")
print("Cr√©dit moyen:", f"{df['AMT_CREDIT'].mean():,.0f}‚Ç¨")
print("Ratio cr√©dit/revenus moyen:", f"{df['CREDIT_INCOME_RATIO'].mean():.1f}x")
print("√Çge moyen:", f"{df['AGE_YEARS'].mean():.0f} ans")
print("Anciennet√© moyenne:", f"{df['EMPLOYMENT_YEARS'].mean():.1f} ans")

# 2. PR√âPARATION DES DONN√âES POUR L'ENTRA√éNEMENT
print("\nüéØ PR√âPARATION POUR L'ENTRA√éNEMENT")
print("="*40)

# S√©paration des features et de la cible
X = df[feature_names].copy()
y = df['TARGET'].copy()

print(f"üìä Features shape: {X.shape}")
print(f"üéØ Target shape: {y.shape}")

# V√©rification des valeurs manquantes
print(f"üîç Valeurs manquantes: {X.isnull().sum().sum()}")

# Division train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"‚úÖ Train set: {X_train.shape}")
print(f"‚úÖ Test set: {X_test.shape}")

# 3. STANDARDISATION DES DONN√âES
print("\n‚öñÔ∏è STANDARDISATION")
print("="*20)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("‚úÖ Standardisation appliqu√©e")

# 4. ENTRA√éNEMENT DU MOD√àLE
print("\nü§ñ ENTRA√éNEMENT DU MOD√àLE")
print("="*30)

# Mod√®le Random Forest compatible scikit-learn 1.3.2
model = RandomForestClassifier(
    n_estimators=100,       # Nombre d'arbres
    max_depth=15,           # Profondeur max
    min_samples_split=10,   # Min √©chantillons pour split
    min_samples_leaf=5,     # Min √©chantillons par feuille
    random_state=42,        # Reproductibilit√©
    n_jobs=-1              # Utiliser tous les CPU
)

print("üîÑ Entra√Ænement en cours...")
model.fit(X_train_scaled, y_train)
print("‚úÖ Mod√®le entra√Æn√©!")

# 5. √âVALUATION DU MOD√àLE
print("\nüìä √âVALUATION")
print("="*15)

# Pr√©dictions
train_score = model.score(X_train_scaled, y_train)
test_score = model.score(X_test_scaled, y_test)

print(f"üéØ Score Train: {train_score:.3f}")
print(f"üéØ Score Test: {test_score:.3f}")

# Pr√©dictions pour AUC
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
auc_score = roc_auc_score(y_test, y_pred_proba)

print(f"üìà AUC Score: {auc_score:.3f}")

# Importance des features
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nüîù TOP 5 FEATURES IMPORTANTES:")
for i, row in feature_importance.head(5).iterrows():
    print(f"  {row['feature']}: {row['importance']:.3f}")

# 6. SAUVEGARDE DU MOD√àLE
print("\nüíæ SAUVEGARDE")
print("="*15)

# Cr√©ation du dossier model
os.makedirs('model', exist_ok=True)

# Sauvegarde du mod√®le
with open('model/credit_model_v2.pkl', 'wb') as f:
    pickle.dump(model, f)
print("‚úÖ Mod√®le sauvegard√©: model/credit_model_v2.pkl")

# Sauvegarde du scaler
with open('model/scaler_v2.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("‚úÖ Scaler sauvegard√©: model/scaler_v2.pkl")

# Sauvegarde des noms de features
with open('model/feature_names_v2.pkl', 'wb') as f:
    pickle.dump(feature_names, f)
print("‚úÖ Features sauvegard√©es: model/feature_names_v2.pkl")

# Sauvegarde des encoders (vides pour ce mod√®le simple)
encoders = {
    'gender': None,
    'education': None,
    'income_type': None,
    'family_status': None
}

with open('model/encoders_v2.pkl', 'wb') as f:
    pickle.dump(encoders, f)
print("‚úÖ Encoders sauvegard√©s: model/encoders_v2.pkl")

# 7. TEST DU MOD√àLE
print("\nüß™ TEST DU MOD√àLE")
print("="*20)

# Fonction de test simple
def test_prediction(income, credit_amount, annuity, age, employment_years, gender='M'):
    """Test simple du mod√®le"""
    
    # Calcul des ratios
    credit_income_ratio = credit_amount / income
    annuity_income_ratio = annuity / income
    
    # Cr√©ation du vecteur de features
    features_test = np.array([[
        income,                    # AMT_INCOME_TOTAL
        credit_amount,             # AMT_CREDIT
        annuity,                   # AMT_ANNUITY
        age,                       # AGE_YEARS
        employment_years,          # EMPLOYMENT_YEARS
        credit_income_ratio,       # CREDIT_INCOME_RATIO
        annuity_income_ratio,      # ANNUITY_INCOME_RATIO
        2,                         # FAMILY_SIZE (d√©faut)
        0.5,                       # CHILDREN_RATIO (d√©faut)
        0.5,                       # EXTERNAL_SOURCES_MEAN (d√©faut)
        1,                         # EDUCATION_ENCODED (d√©faut)
        1,                         # INCOME_TYPE_ENCODED (d√©faut)
        1,                         # FAMILY_STATUS_ENCODED (d√©faut)
        1 if gender == 'M' else 0  # CODE_GENDER
    ]])
    
    # Standardisation
    features_scaled = scaler.transform(features_test)
    
    # Pr√©diction
    risk_proba = model.predict_proba(features_scaled)[0][1]
    risk_score = int(risk_proba * 100)
    
    return risk_score, risk_proba

# Tests avec diff√©rents profils
print("Profil 1 - Bon client:")
score1, proba1 = test_prediction(50000, 150000, 1200, 35, 5)
print(f"  Score: {score1}%, Probabilit√©: {proba1:.3f}")

print("Profil 2 - Client risqu√©:")
score2, proba2 = test_prediction(25000, 200000, 1800, 22, 0)
print(f"  Score: {score2}%, Probabilit√©: {proba2:.3f}")

print("Profil 3 - Client excellent:")
score3, proba3 = test_prediction(80000, 200000, 1500, 40, 10)
print(f"  Score: {score3}%, Probabilit√©: {proba3:.3f}")

print("\nüéâ MOD√àLE CR√â√â AVEC SUCC√àS!")
print("="*30)
print("‚úÖ Mod√®le compatible scikit-learn 1.3.2")
print("‚úÖ Tous les fichiers sauvegard√©s dans model/")
print("‚úÖ Pr√™t pour Streamlit Cloud")
print(f"‚úÖ Version sklearn utilis√©e: {sklearn.__version__}")

print("\nüìÅ Fichiers cr√©√©s:")
print("  - model/credit_model_v2.pkl")
print("  - model/scaler_v2.pkl")
print("  - model/feature_names_v2.pkl")
print("  - model/encoders_v2.pkl")
